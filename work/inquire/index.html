<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="/style.css">
    <title>Inquire - Glenn's Notepad</title>
    <meta charset="UTF-8">
    <meta name="author" content="Glenn Bitar">
</head>

<body>
    <header>
        <h1>Glenn's Notepad</h1>
    </header>
    <nav>
        <a href="/">Home</a>
    </nav>
    <main>
        <article>
            <header>
                <h2>Inquire</h2>
                <div class="article-metadata">
                    Published <time datetime="2025-08-03">August 3, 2025</time>.
                </div>
            </header>
            <section>
                <h3>TLDR</h3>
                <p>
                    During 2024 and 2025 I led the design and development of <em>Inquire</em>, a centralized user data
                    service powering personalization across more than 100 local newspapers.
                </p>
                <ul>
                    <li>
                        Adopted an entity-attribute-value (EAV) data model for flexibility and rapid onboarding of new
                        user attributes.
                    </li>
                    <li>
                        Built an attribute catalog and intuitive management dashboard to enable high degree of
                        self-service
                        and reduce platform bottlenecks.
                    </li>
                    <li>
                        Integrated metrics to provide data owners with high-resolution insights into usage patterns.
                    </li>
                    <li>
                        Incorporated user consent data, ensuring compliant and confident data access for consumers.
                    </li>
                    <li>
                        Implemented in-flight type checking to guarantee the correctness of delivered data.
                    </li>
                </ul>
            </section>
            <section>
                <h3>Background</h3>
                <p>
                    At <a href="https://www.amedia.no/">Amedia</a>, we host and develop for more than 100 local
                    newspaper across Norway.
                    A portion of Amedia's success is owed to partially personalized front pages, along with personalized
                    marketing and communications.
                    Amedia's backend is a collection of (micro) services called in a variety of situations, e.g., to
                    serve the contents of an article, a front-page teaser, or marketing messages.
                </p>
                <p>
                    Since each page load is partially tailored to the logged in user, many of the backend services
                    require attributes of the user in order to function optimally.
                    Much of this data lives in our data lake, which is not optimized for fast, single-row acces (i.e.,
                    data for a single user).
                </p>
                <p>
                    To support in-flight requests for user analytics, Amedia has over the course of several years
                    developed multiple services that host selections of user attributes for fast access.
                    <em>Inquire</em> is the third iteration of a user data service, and was made to address some
                    challenges that were revealed along the way:
                </p>
                <dl>
                    <dt>Need for high-resolution usage metrics</dt>
                    <dd>
                        Not having usage metrics on the attribute level left us searching in our codebases for whether
                        or not an attribute was used if we wanted to retire it.
                        Combined with each request returning <em>all</em> user data, it made attribute usage information
                        hard to find.
                    </dd>

                    <dt>Out-of-band consent data</dt>
                    <dd>
                        Whether the user consented to use of attributes for personalized ads, communications, marketing
                        or editorial content had to be requested from separate services.
                        This caused unnecessary complexity for data consumers.
                    </dd>

                    <dt>Platform bottleneck</dt>
                    <dd>
                        Appending user attributes required significant work for the maintaining platform team.
                        One column per user attribute implied schema migrations and accompanying application code
                        changes whenever, e.g., a marketing team wanted to test new personalized messages.
                        The fast pace of these teams are important for the organization.
                    </dd>
                </dl>
                <p>
                    While the previous iterations of the user data services have provided tremendous value for Amedia,
                    Inquire was built to confront the challenges listed above.
                </p>
            </section>

            <section>
                <h3>System overview</h3>
                <p>
                    Inquire consists of a central <strong>Postgres database</strong>, an <strong>HTTP/JSON
                        service</strong> that serves user data to downstream consumers, and a suite of support
                    components:
                </p>
                <dl>
                    <dt>Batch ingestion pipeline</dt>
                    <dd>for periodic loading from the data lake.</dd>

                    <dt>Stream ingestion pipeline</dt>
                    <dd>for real-time updates (e.g., user consent).</dd>

                    <dt>Management dashboard</dt>
                    <dd>for attribute onboarding and observability.</dd>
                </dl>
                <p>
                    Inquire is a system composed of a central database containing the user data and attribute catalogs,
                    a HTTP/JSON service that serves this data to logged-in clients and other backend services,
                    and multiple support components, including a management dashboard and pipelines for batch and stream
                    ingestion.
                </p>
                <p>
                    Almost all user analytics data lives in Google BigQuery, and is updated at most daily.
                    The batch ingest pipeline regularly checks source tables for updates and makes sure that the latest
                    data is imported to the Inquire database.
                    Other data, user consents, are retrieved from message queues via the stream ingestor, immediately
                    following changes to the user's preferences.
                </p>
                <p>
                    The database schema is based on the <a
                        href="https://en.wikipedia.org/wiki/Entity%E2%80%93attribute%E2%80%93value_model">entity-attribute-value</a>
                    (EAV) model, where the main database table has one row per user per attribute, and a single data
                    value column.
                    The value column is <code>jsonb</code> (this is a Postgres database), allowing for a variety of
                    stored data types.
                </p>
            </section>
            <section>
                <h3>Key challenges</h3>
                A selection of key challenges and areas where I had important contributions and learnings.
                <section>
                    <h4>Navigating our internal development platform</h4>
                    <p>
                        Amedia is my first job focused mainly on web development.
                        Having a background from research and robotics, I had very little in-depth experience with
                        topics like HTTP, REST (whatever that means), databases, and caching.
                        Amedia is an organization where it's possible to move fast and spin up new backends to solve
                        narrow problems on a whim.
                        This also means that cohesion and uniformity is not the main priority.
                        The GitHub organization has close to a thousand repositories in
                        <span
                            title="In my very short investigation, I found the following languages: Python, Rust, Go, Kotlin, Java, Javascript, Clojure, Swift, Typescript, Dart, Scala, Php, Ruby.">than
                            13 languages(!)
                        </span>.
                    </p>
                    <p>
                        As the sole developer on our data platform team with the time and motivation for developing API
                        services, moving from task to deployment was a challenge.
                        Especially since most of the consepts were new to me.
                        When I started this work, much of the knowledge needed to deploy a service was distributed among
                        the many teams, and a uniform guide or a "golden path" did not exist.
                        For a while I was the annoying guy constantly asking questions to our IDP team to get from start
                        to finish.
                    </p>
                </section>
                <section id="flexible-data-modeling-with-eav">
                    <h4>Flexible data modeling with EAV</h4>
                    <p>
                        A key design choice in Inquire is an entity-attribute-value data model.
                        This removes the need for schema migrations or application changes changes when a new attribute
                        is added.
                        Each row contains a user ID, an attribute ID which references an attribute catalog, metadata
                        describing when data was updated and when it becomes stale, and the data value itself, stored as
                        JSON.
                        The attribute catalog contains a human-readable name and expected type information.
                    </p>
                </section>
                <section>
                    <h4>Consent integration</h4>
                    <p>
                        In addition to the main data table and the attribute catalog, we have a table describing
                        data usage <em>purposes</em>, where we can map user consent to attributes.
                        A user opts in to or out of separate purposes, so the same attribute for a given user may be
                        available under the <em>editorial</em> purpose but <var>null</var> under the <em>marketing</em>
                        purpose.
                    </p>
                    <p>
                        Some attributes are only allowed to be used under certain purposes.
                        For example, we allow the <code>sports_affinity</code> under the <em>editorial</em> purpose
                        (given the user opts in to personalization for that purpose), while letting it be completely
                        unavailable under the <em>ads</em> purpose.
                    </p>
                </section>
                <section>
                    <h4>Composed attributes</h4>
                    <p>
                        Some user attributes are functions of multiple points of data.
                        For instance, a user changing their newspaper subscription plan is a rare occurence, therefore,
                        the <code>subscription_plan_batch</code> attribute is based on a table in our data lake, which
                        is updated and ingested nightly.
                        However, we also receive events when this happens, which creates or updates the
                        <code>subscription_plan_stream</code> attribute.
                    </p>
                    <p>
                        To streamline how the consumers use this data, they only see <em>virtual</em> user attributes,
                        which are functions of the <em>physical</em> attributes we have talked about up until now.
                        A virtual attribute has an ordered list of physical attributes.
                        A virtual attribute's value resolves to one of the physical values depending on the chosen
                        <em>selection strategy</em> for that virtual attribute:
                    </p>
                    <dl>
                        <dt>Coalesce</dt>
                        <dd>The first non-null value in the ordered list of physical attributes.</dd>

                        <dt>Newest</dt>
                        <dd>The newest non-null value among the list of physical attributes. Order is ignored.</dd>

                        <dt>Special</dt>
                        <dd>
                            Value selection or composition is hard-coded in the application, i.e., not configurable at
                            runtime.
                        </dd>
                    </dl>
                </section>
                <section>
                    <h4>Easy-to-use management dashboard</h4>
                    <p>
                        Our flexible data model gives us the power to add attributes, modify their composition or type,
                        associate them with purposes and consent data.
                        To make this easy, we have developed a management dashboard that streamlines common operations
                        and gives us an overview of attributes and data freshness.
                    </p>
                    <p>
                        The management dashboard is a server-side rendered website with <a
                            href="https://htmx.org/">htmx</a>
                        for dynamic content.
                    </p>
                    <p>
                        The dashboard has list pages for the physical and virtual attribute catalogs, purposes, and
                        ingest jobs.
                        Each attribute entry has a detail page and an edit page.
                        Each purpose can also be edited, and each job has a detail page.
                        It's also possible to add new attributes via the dashboard.
                        Every developer in our organization can view all data, but only data platform developers can
                        POST to the edit and new endpoints.
                    </p>
                    <p>
                        The management dashboard allows us to swiftly carry out necessary modifications, and lets us get
                        fast overviews of the data in our service.
                    </p>
                </section>
                <section>
                    <h4>Type checking of attribute values</h4>
                    <p>
                        The <a href="#flexible-data-modeling-with-eav">EAV data model</a> we use store attribute values
                        as JSON in the database.
                        This is great for flexibility, but sacrifices type safety at rest.
                        To simplify the batch ingestor pipeline, we do not have type checking of the data imported from
                        our data lake.
                        (The data in our data lake is, however, typed.)
                        Instead, we type check the JSON data on every query from consumers, and log fatal errors if a
                        discrepancy from the expected type (as stored in the attribute catalog) should be found.
                    </p>
                    <p>
                        To date, after nearly one year of operation with approximately 250 requests per second on
                        average over 30 attributes, we have not had a single instance of wrong typing.
                        This has given us confidence in that the tradeoff for flexibility against rigidness has been
                        worthwhile.
                    </p>
                </section>
                <section>
                    <h4>High-resolution metrics</h4>
                    <p>
                        We have metrics recording the use of each virtual attribute per consumer per purpose.
                        Additionally, we record whether or not a request for an attribute returned a null value or
                        actual data.
                        This allows us to answer questions like these:
                    </p>
                    <ul>
                        <li>Which attributes are currently in use by any consumer?</li>
                        <li>Which consumers use a certain attribute?</li>
                        <li>For what purpose does a certain consumer use data?</li>
                        <li>What attribute does a certain consumer use?</li>
                        <li>An attribute's hit rate suddenly dropped to 0%, why?</li>
                    </ul>
                    <p>
                        This helps us coordinate with consumers when a certain attribute needs to be retired, be aware
                        of when attribute data went stale, monitor compliance of our privacy policy, and more.
                    </p>
                </section>
                <em>
                    <h4>In-memory caching for performance</h4>
                    <p>TODO</p>
                </em>
            </section>
        </article>
    </main>
</body>

</html>